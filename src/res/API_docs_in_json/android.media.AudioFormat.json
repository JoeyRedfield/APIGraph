{"Functions": {"AudioFormat()": {"Returns": [], "Parameters": [], "Throws": [], "SeeAlso": [], "Permissions": [], "Description": "", "history": "Added in API level 3", "FullName": "public AudioFormat ()"}, "writeToParcel(android.os.Parcel, int)": {"Returns": [], "Parameters": [["@B_android#os#Parcel_E@", "Parcel: The Parcel in which the object should be written."], ["int", "int: Additional flags about how the object should be written. May be 0 or @B_android#os#Parcelable#PARCELABLE_WRITE_RETURN_VALUE_E@."]], "Throws": [], "SeeAlso": [], "Permissions": [], "Description": "Flatten this object in to a Parcel.", "history": "added in API level 24", "FullName": "public void writeToParcel (Parcel dest, int flags)"}, "getChannelIndexMask()": {"Returns": [["int", "one of the values that can be set in @B_android#media#AudioFormat#Builder#setChannelIndexMask_E@ or @B_android#media#AudioFormat#CHANNEL_INVALID_E@ if not set or an invalid mask was used."]], "Parameters": [], "Throws": [], "SeeAlso": [], "Permissions": [], "Description": "Return the channel index mask. See the section on @B_android#media#AudioFormat#getChannelMask_E@).", "history": "Added in API level 23", "FullName": "public int getChannelIndexMask ()"}, "describeContents()": {"Returns": [["int", "a bitmask indicating the set of special object types marshaled by this Parcelable object instance. Value is either 0 or @B_android#os#Parcelable#CONTENTS_FILE_DESCRIPTOR_E@"]], "Parameters": [], "Throws": [], "SeeAlso": [], "Permissions": [], "Description": "Describe the kinds of special objects contained in this Parcelable instance's marshaled representation. For example, if the object will include a file descriptor in the output of @B_android#os#Parcelable#writeToParcel_E@, the return value of this method must include the @B_android#os#Parcelable#CONTENTS_FILE_DESCRIPTOR_E@ bit.", "history": "Added in API level 24", "FullName": "public int describeContents ()"}, "getFrameSizeInBytes()": {"Returns": [["int", "The audio frame size in bytes corresponding to the encoding and the channel mask. Value is 1 or greater"]], "Parameters": [], "Throws": [], "SeeAlso": [], "Permissions": [], "Description": "Return the frame size in bytes. For PCM or PCM packed compressed data this is the size of a sample multiplied by the channel count. For all other cases, including invalid/unset channel masks, this will return 1 byte. As an example, a stereo 16-bit PCM format would have a frame size of 4 bytes, an 8 channel float PCM format would have a frame size of 32 bytes, and a compressed data format (not packed in PCM) would have a frame size of 1 byte. Both @B_android#media#AudioRecord_E@ or @B_android#media#AudioTrack_E@ process data in multiples of this frame size.", "history": "Added in API level 29", "FullName": "public int getFrameSizeInBytes ()"}, "getChannelMask()": {"Returns": [["int", "one of the values that can be set in @B_android#media#AudioFormat#Builder#setChannelMask_E@ or @B_android#media#AudioFormat#CHANNEL_INVALID_E@ if not set."]], "Parameters": [], "Throws": [], "SeeAlso": [], "Permissions": [], "Description": "Return the channel mask. See the section on @B_android#media#AudioFormat#getChannelIndexMask_E@) and the position-based mask returned by this function.", "history": "Added in API level 21", "FullName": "public int getChannelMask ()"}, "toString()": {"Returns": [["@B_java#lang#String_E@", "a string representation of the object."]], "Parameters": [], "Throws": [], "SeeAlso": [], "Permissions": [], "Description": "Returns a string representation of the object. In general, the toString method returns a string that \"textually represents\" this object. The result should be a concise but informative representation that is easy for a person to read. It is recommended that all subclasses override this method. The toString method for class Object returns a string consisting of the name of the class of which the object is an instance, the at-sign character `@', and the unsigned hexadecimal representation of the hash code of the object. In other words, this method returns a string equal to the value of:", "history": "Added in API level 3", "FullName": "public String toString ()"}, "getEncoding()": {"Returns": [["int", "one of the values that can be set in @B_android#media#AudioFormat#Builder#setEncoding_E@ or @B_android#media#AudioFormat#ENCODING_INVALID_E@ if not set."]], "Parameters": [], "Throws": [], "SeeAlso": [], "Permissions": [], "Description": "Return the encoding. See the section on", "history": "Added in API level 21", "FullName": "public int getEncoding ()"}, "getChannelCount()": {"Returns": [["int", "the channel count derived from the channel position mask or the channel index mask. Zero is returned if both the channel position mask and the channel index mask are not set."]], "Parameters": [], "Throws": [], "SeeAlso": [], "Permissions": [], "Description": "Return the channel count.", "history": "Added in API level 23", "FullName": "public int getChannelCount ()"}, "equals(java.lang.Object)": {"Returns": [["boolean", "true if this object is the same as the obj argument; false otherwise."]], "Parameters": [["@B_java#lang#Object_E@", "Object: the reference object with which to compare."]], "Throws": [], "SeeAlso": [], "Permissions": [], "Description": "Indicates whether some other object is \"equal to\" this one. The equals method implements an equivalence relation on non-null object references: It is x, x.equals(x) should return true. It is x and y, x.equals(y) should return true if and only if y.equals(x) returns true. It is x, y, and z, if x.equals(y) returns true and y.equals(z) returns true, then x.equals(z) should return true. It is x and y, multiple invocations of x.equals(y) consistently return true or consistently return false, provided no information used in equals comparisons on the objects is modified. For any non-null reference value x, x.equals(null) should return false. The equals method for class Object implements the most discriminating possible equivalence relation on objects; that is, for any non-null reference values x and y, this method returns true if and only if x and y refer to the same object (x == y has the value true). Note that it is generally necessary to override the hashCode method whenever this method is overridden, so as to maintain the general contract for the hashCode method, which states that equal objects must have equal hash codes.", "history": "Added in API level 3", "FullName": "public boolean equals (Object o)"}, "getSampleRate()": {"Returns": [["int", "one of the values that can be set in @B_android#media#AudioFormat#Builder#setSampleRate_E@ or @B_android#media#AudioFormat#SAMPLE_RATE_UNSPECIFIED_E@ if not set."]], "Parameters": [], "Throws": [], "SeeAlso": [], "Permissions": [], "Description": "Return the sample rate.", "history": "Added in API level 21", "FullName": "public int getSampleRate ()"}, "writeToParcel(android.os.Parcel,int)": {"Returns": [], "Parameters": [["@B_android#os#Parcel_E@", "Parcel: The Parcel in which the object should be written."], ["int", "int: Additional flags about how the object should be written. May be 0 or @B_android#os#Parcelable#PARCELABLE_WRITE_RETURN_VALUE_E@. Value is either 0 or a combination of @B_android#os#Parcelable#PARCELABLE_WRITE_RETURN_VALUE_E@, and android.os.Parcelable.PARCELABLE_ELIDE_DUPLICATES"]], "Throws": [], "SeeAlso": [], "Permissions": [], "Description": "Flatten this object in to a Parcel.", "history": "Added in API level 24", "FullName": "public void writeToParcel (Parcel dest, int flags)"}, "hashCode()": {"Returns": [["int", "a hash code value for this object."]], "Parameters": [], "Throws": [], "SeeAlso": [], "Permissions": [], "Description": "Returns a hash code value for the object. This method is supported for the benefit of hash tables such as those provided by @B_java#util#HashMap_E@. The general contract of hashCode is: Whenever it is invoked on the same object more than once during an execution of a Java application, the hashCode method must consistently return the same integer, provided no information used in equals comparisons on the object is modified. This integer need not remain consistent from one execution of an application to another execution of the same application. If two objects are equal according to the equals(Object) method, then calling the hashCode method on each of the two objects must produce the same integer result. It is not required that if two objects are unequal according to the @B_java#lang#Object#equals_E@ method, then calling the hashCode method on each of the two objects must produce distinct integer results. However, the programmer should be aware that producing distinct integer results for unequal objects may improve the performance of hash tables. As much as is reasonably practical, the hashCode method defined by class Object does return distinct integers for distinct objects. (This is typically implemented by converting the internal address of the object into an integer, but this implementation technique is not required by the Java\u2122 programming language.)", "history": "Added in API level 3", "FullName": "public int hashCode ()"}}, "Inheritance": [], "ClassName": "android.media.AudioFormat", "ClassDesc": "The @B_android#media#AudioFormat_E@ class is used to access a number of audio format and channel configuration constants. They are for instance used in @B_android#media#AudioTrack_E@ and @B_android#media#AudioRecord_E@, as valid values in individual parameters of constructors like @B_android#media#AudioTrack#AudioTrack_E@, where the fourth parameter is one of the AudioFormat.ENCODING_* constants. The AudioFormat constants are also used in @B_android#media#MediaFormat_E@ to specify audio related values commonly used in media, such as for @B_android#media#MediaFormat#KEY_CHANNEL_MASK_E@. The @B_android#media#AudioFormat#Builder_E@ class can be used to create instances of the AudioFormat format class. Refer to @B_android#media#AudioFormat#Builder_E@ for documentation on the mechanics of the configuration and building of such instances. Here we describe the main concepts that the AudioFormat class allow you to convey in each instance, they are: Closely associated with the AudioFormat is the notion of an Expressed in Hz, the sample rate in an AudioFormat instance expresses the number of audio samples for each channel per second in the content you are playing or recording. It is not the sample rate at which content is rendered or produced. For instance a sound at a media sample rate of 8000Hz can be played on a device operating at a sample rate of 48000Hz; the sample rate conversion is automatically handled by the platform, it will not play at 6x speed. As of API @B_android#os#Build#VERSION_CODES#M_E@, sample rates up to 192kHz are supported for AudioRecord and AudioTrack, with sample rate conversion performed as needed. To improve efficiency and avoid lossy conversions, it is recommended to match the sample rate for AudioRecord and AudioTrack to the endpoint device sample rate, and limit the sample rate to no more than 48kHz unless there are special device capabilities that warrant a higher rate. Audio encoding is used to describe the bit representation of audio data, which can be either linear PCM or compressed audio, such as AC3 or DTS. For linear PCM, the audio encoding describes the sample size, 8 bits, 16 bits, or 32 bits, and the sample representation, integer or float. @B_android#media#AudioFormat#ENCODING_PCM_8BIT_E@: The audio sample is a 8 bit unsigned integer in the range [0, 255], with a 128 offset for zero. This is typically stored as a Java byte in a byte array or ByteBuffer. Since the Java byte is signed, be careful with math operations and conversions as the most significant bit is inverted. @B_android#media#AudioFormat#ENCODING_PCM_16BIT_E@: The audio sample is a 16 bit signed integer typically stored as a Java short in a short array, but when the short is stored in a ByteBuffer, it is native endian (as compared to the default Java big endian). The short has full range from [-32768, 32767], and is sometimes interpreted as fixed point Q.15 data. @B_android#media#AudioFormat#ENCODING_PCM_FLOAT_E@: Introduced in API @B_android#os#Build#VERSION_CODES#LOLLIPOP_E@, this encoding specifies that the audio sample is a 32 bit IEEE single precision float. The sample can be manipulated as a Java float in a float array, though within a ByteBuffer it is stored in native endian byte order. The nominal range of ENCODING_PCM_FLOAT audio data is [-1.0, 1.0]. It is implementation dependent whether the positive maximum of 1.0 is included in the interval. Values outside of the nominal range are clamped before sending to the endpoint device. Beware that the handling of NaN is undefined; subnormals may be treated as zero; and infinities are generally clamped just like other values for AudioTrack \u2013 try to avoid infinities because they can easily generate a NaN. To achieve higher audio bit depth than a signed 16 bit integer short, it is recommended to use ENCODING_PCM_FLOAT for audio capture, processing, and playback. Floats are efficiently manipulated by modern CPUs, have greater precision than 24 bit signed integers, and have greater dynamic range than 32 bit signed integers. AudioRecord as of API @B_android#os#Build#VERSION_CODES#M_E@ and AudioTrack as of API @B_android#os#Build#VERSION_CODES#LOLLIPOP_E@ support ENCODING_PCM_FLOAT. For compressed audio, the encoding specifies the method of compression, for example @B_android#media#AudioFormat#ENCODING_AC3_E@ and @B_android#media#AudioFormat#ENCODING_DTS_E@. The compressed audio data is typically stored as bytes in a byte array or ByteBuffer. When a compressed audio encoding is specified for an AudioTrack, it creates a direct (non-mixed) track for output to an endpoint (such as HDMI) capable of decoding the compressed audio. For (most) other endpoints, which are not capable of decoding such compressed audio, you will need to decode the data first, typically by creating a @B_android#media#MediaCodec_E@. Alternatively, one may use @B_android#media#MediaPlayer_E@ for playback of compressed audio files or streams. When compressed audio is sent out through a direct AudioTrack, it need not be written in exact multiples of the audio access unit; this differs from MediaCodec input buffers. Channel masks are used in AudioTrack and AudioRecord to describe the samples and their arrangement in the audio frame. They are also used in the endpoint (e.g. a USB audio interface, a DAC connected to headphones) to specify allowable configurations of a particular device. As of API @B_android#os#Build#VERSION_CODES#M_E@, there are two types of channel masks: channel position masks and channel index masks. @B_android#os#Build#VERSION_CODES#BASE_E@. For input and output, they imply a positional nature - the location of a speaker or a microphone for recording or playback. For a channel position mask, each allowed channel position corresponds to a bit in the channel mask. If that channel position is present in the audio frame, that bit is set, otherwise it is zero. The order of the bits (from lsb to msb) corresponds to the order of that position's sample in the audio frame. The canonical channel position masks by channel count are as follows: These masks are an ORed composite of individual channel masks. For example @B_android#media#AudioFormat#CHANNEL_OUT_STEREO_E@ is composed of @B_android#media#AudioFormat#CHANNEL_OUT_FRONT_LEFT_E@ and @B_android#media#AudioFormat#CHANNEL_OUT_FRONT_RIGHT_E@. @B_android#os#Build#VERSION_CODES#M_E@. They allow the selection of a particular channel from the source or sink endpoint by number, i.e. the first channel, the second channel, and so forth. This avoids problems with artificially assigning positions to channels of an endpoint, or figuring what the iHere's an example where channel index masks address this confusion: dealing with a 4 channel USB device. Using a position mask, and based on the channel count, this would be a @B_android#media#AudioFormat#CHANNEL_OUT_QUAD_E@ device, but really one is only interested in channel 0 through channel 3. The USB device would then have the following individual bit channel masks: @B_android#media#AudioFormat#CHANNEL_OUT_FRONT_LEFT_E@, @B_android#media#AudioFormat#CHANNEL_OUT_FRONT_RIGHT_E@, @B_android#media#AudioFormat#CHANNEL_OUT_BACK_LEFT_E@ and @B_android#media#AudioFormat#CHANNEL_OUT_BACK_RIGHT_E@. But which is channel 0 and which is channel 3? For a channel index mask, each channel number is represented as a bit in the mask, from the lsb (channel 0) upwards to the msb, numerically this bit value is 1 << channelNumber. A set bit indicates that channel is present in the audio frame, otherwise it is cleared. The order of the bits also correspond to that channel number's sample order in the audio frame. For the previous 4 channel USB device example, the device would have a channel index mask 0xF. Suppose we wanted to select only the first and the third channels; this would correspond to a channel index mask 0x5 (the first and third bits set). If an AudioTrack uses this channel index mask, the audio frame would consist of two samples, the first sample of each frame routed to channel 0, and the second sample of each frame routed to channel 2. The canonical channel index masks by channel count are given by the formula (1 << channelCount) - 1. CHANNEL_OUT_FRONT_LEFT, CHANNEL_OUT_FRONT_CENTER, etc. for HDMI home theater purposes. AudioTrack to output movie content, where 5.1 multichannel output is to be written. AudioRecord may only want the third and fourth audio channels of the endpoint (i.e. the second channel pair), and not care the about position it corresponds to, in which case the channel index mask is 0xC. Multichannel AudioRecord sessions should use channel index masks. For linear PCM, an audio frame consists of a set of samples captured at the same time, whose count and channel association are given by the @B_android#media#MediaCodec_E@), or a single byte of compressed data (e.g. @B_android#media#AudioTrack#getBufferSizeInFrames_E@), or the linear PCM frame result from decoding the compressed data (e.g.@B_android#media#AudioTrack#getPlaybackHeadPosition_E@), depending on the context where audio frame is used. For the purposes of @B_android#media#AudioFormat#getFrameSizeInBytes_E@, a compressed data format returns a frame size of 1 byte."}